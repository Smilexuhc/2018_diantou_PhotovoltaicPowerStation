{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 团队版本1.0测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/python/Envs/competitions/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/python/Envs/competitions/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/python/Envs/competitions/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# 2. Import libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "# 简单数据分层\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 数据预处理\n",
    "from sklearn import preprocessing\n",
    "# 模型选择 随机森林回归\n",
    "from sklearn import RandomForestRegressor\n",
    "# 数据处理 pipeline 管道\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# 模型参数自动调节\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 计算拟合度与根均方误差\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# 模型保存\n",
    "from sklearn.externals import joblib\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load red wine data.\n",
    "# dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "# data = pd.read_csv(dataset_url, sep=';')\n",
    "\n",
    "train_data = pd.read_csv('../data/public.train.csv')\n",
    "test_data = pd.read_csv('../data/public.test.csv')\n",
    "submit = pd.read_csv('../data/submit_example.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split data into training and test sets\n",
    "y = train_data['发电量']\n",
    "X = train_data.drop(['ID','发电量'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))\n",
    "\n",
    "hyperparameters = { 'randomforestregressor__max_features' : [ 'sqrt'],\n",
    "                  'randomforestregressor__max_depth': [None]}\n",
    "\n",
    "\n",
    "# 5. Declare data preprocessing steps\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))\n",
    " \n",
    "# 6. Declare hyperparameters to tune\n",
    "hyperparameters = { 'randomforestregressor__max_features' : [ 'sqrt'],\n",
    "                  'randomforestregressor__max_depth': [None]}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decr...mators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'randomforestregressor__max_features': ['sqrt'], 'randomforestregressor__max_depth': [None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Tune model using cross-validation pipeline\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)\n",
    " \n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9980366270247928\n",
      "0.02373437447432535\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluate model pipeline on test data\n",
    "pred = clf.predict(X_test)\n",
    "print (r2_score(y_test, pred))\n",
    "print (mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Save model for future use\n",
    "joblib.dump(clf, 'rf_regressor.pkl')\n",
    "# To load: clf2 = joblib.load('rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. 将test_data的训练数据输入模型，计算出结果，并保存\n",
    "\n",
    "clf = joblib.load(\"rf_regressor.pkl\")\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ID'] = list(test_data['ID'])\n",
    "test_feature = test_data.drop('ID', axis=1)\n",
    "pre = clf.predict(test_feature)\n",
    "\n",
    "df_result['Score'] = pre\n",
    "df_result.to_csv('./submit/submit_version1.csv', index=False, header=False, float_format='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768158859699201\n"
     ]
    }
   ],
   "source": [
    "print(1 / (1 + 0.02373437447432535))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练出来的模型与给出的测试集, 拟合度很高0.97~0.98 但是实际上只有0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
